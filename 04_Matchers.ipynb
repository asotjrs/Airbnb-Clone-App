{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ/4Kqz3BnQP7G6iBqD/R0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asotjrs/Airbnb-Clone-App/blob/master/04_Matchers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#the spaCy Matcher"
      ],
      "metadata": {
        "id": "TUpMWd3h__S-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRqgx2Xf_2iv",
        "outputId": "70c133b4-1d1c-4268-e95e-03636e5688e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(16571425990740197027, 6, 7)]\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "#Basic example\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LIKE_EMAIL\": True}]\n",
        "matcher.add(\"EMAIL_ADDRESS\", [pattern])\n",
        "doc = nlp(\"This is an email address: wmattingly@aol.com\")\n",
        "matches = matcher(doc)\n",
        "print (matches)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lexeme, start token, end token\n",
        "\n"
      ],
      "metadata": {
        "id": "7izOIQMI_-nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab[matches[0][0]].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DSWZglX-AeUJ",
        "outputId": "931997b1-8697-48a6-9f6a-c68e8ac564be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'EMAIL_ADDRESS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applied Matcher"
      ],
      "metadata": {
        "id": "WM7UEjTmBJsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"data/wiki_mlk.txt\", \"r\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "pMnaRawDAoDC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "YZaIG4XzBiqm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grabbing all of the propper nouns\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern])\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLw4f6PaBl3r",
        "outputId": "5094c943-3b2e-4c0b-98fd-7dbe02d0d0f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n",
            "(3232560085755078826, 0, 1) Martin\n",
            "(3232560085755078826, 1, 2) Luther\n",
            "(3232560085755078826, 2, 3) King\n",
            "(3232560085755078826, 3, 4) Jr.\n",
            "(3232560085755078826, 6, 7) Michael\n",
            "(3232560085755078826, 7, 8) King\n",
            "(3232560085755078826, 8, 9) Jr.\n",
            "(3232560085755078826, 10, 11) January\n",
            "(3232560085755078826, 15, 16) April\n",
            "(3232560085755078826, 23, 24) Baptist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improving it with Multi-Word Tokens"
      ],
      "metadata": {
        "id": "1pET7snLDpUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern])\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSG7gRJhB0Dx",
        "outputId": "58357d6c-de6c-43a0-f0a1-a2401d68632c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175\n",
            "(3232560085755078826, 0, 1) Martin\n",
            "(3232560085755078826, 0, 2) Martin Luther\n",
            "(3232560085755078826, 1, 2) Luther\n",
            "(3232560085755078826, 0, 3) Martin Luther King\n",
            "(3232560085755078826, 1, 3) Luther King\n",
            "(3232560085755078826, 2, 3) King\n",
            "(3232560085755078826, 0, 4) Martin Luther King Jr.\n",
            "(3232560085755078826, 1, 4) Luther King Jr.\n",
            "(3232560085755078826, 2, 4) King Jr.\n",
            "(3232560085755078826, 3, 4) Jr.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greedy Keyword Argument"
      ],
      "metadata": {
        "id": "UONlNcn5D1HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jakgEuZCDu2r",
        "outputId": "373e436a-1b69-4e5b-f191-0c938ee191cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n",
            "(3232560085755078826, 83, 88) Martin Luther King Sr.\n",
            "(3232560085755078826, 469, 474) Martin Luther King Jr. Day\n",
            "(3232560085755078826, 536, 541) Martin Luther King Jr. Memorial\n",
            "(3232560085755078826, 0, 4) Martin Luther King Jr.\n",
            "(3232560085755078826, 128, 132) Southern Christian Leadership Conference\n",
            "(3232560085755078826, 247, 251) Director J. Edgar Hoover\n",
            "(3232560085755078826, 6, 9) Michael King Jr.\n",
            "(3232560085755078826, 325, 328) Nobel Peace Prize\n",
            "(3232560085755078826, 422, 425) James Earl Ray\n",
            "(3232560085755078826, 463, 466) Congressional Gold Medal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting it to Apperance"
      ],
      "metadata": {
        "id": "d5U_k3eeEDeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key = lambda x: x[1])\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtPbQJ5lD8m9",
        "outputId": "07d93686-1d52-4bb6-f0b8-e7431b6f5ddf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n",
            "(3232560085755078826, 0, 4) Martin Luther King Jr.\n",
            "(3232560085755078826, 6, 9) Michael King Jr.\n",
            "(3232560085755078826, 10, 11) January\n",
            "(3232560085755078826, 15, 16) April\n",
            "(3232560085755078826, 23, 24) Baptist\n",
            "(3232560085755078826, 49, 50) King\n",
            "(3232560085755078826, 69, 71) Mahatma Gandhi\n",
            "(3232560085755078826, 83, 88) Martin Luther King Sr.\n",
            "(3232560085755078826, 89, 90) King\n",
            "(3232560085755078826, 113, 114) King\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}, {\"POS\": \"VERB\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key = lambda x: x[1])\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldiACoVYFc7N",
        "outputId": "c3332810-4238-46fe-ef79-1f83c9f54d3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "(3232560085755078826, 49, 51) King advanced\n",
            "(3232560085755078826, 89, 91) King participated\n",
            "(3232560085755078826, 113, 115) King led\n",
            "(3232560085755078826, 167, 169) King helped\n",
            "(3232560085755078826, 247, 252) Director J. Edgar Hoover considered\n",
            "(3232560085755078826, 322, 324) King won\n",
            "(3232560085755078826, 485, 488) United States beginning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Finding Quotes and Speakers"
      ],
      "metadata": {
        "id": "0fKKQm05GFP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open (\"data/alice.json\", \"r\") as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "t4ijr-NXlvxR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = data[0][2][0]\n",
        "print (text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41bWazlYmD7u",
        "outputId": "269f1880-5b0a-4a01-bba9-122447f0ade8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key = lambda x: x[1])\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NRT9PZCGw9L",
        "outputId": "e7a2fa2c-034a-4afd-951a-c6c913b79a8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(3232560085755078826, 47, 58) 'and what is the use of a book,'\n",
            "(3232560085755078826, 60, 67) 'without pictures or conversation?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Find Speaker"
      ],
      "metadata": {
        "id": "nKgRfvYxG21x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "text = data[0][2][0].replace( \"`\", \"'\")\n",
        "pattern = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key = lambda x: x[1])\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqno6NXPmGs_",
        "outputId": "f23f386b-8959-4870-d8bb-c3ed65ca28c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(3232560085755078826, 47, 58) 'and what is the use of a book,'\n",
            "(3232560085755078826, 60, 67) 'without pictures or conversation?'\n"
          ]
        }
      ]
    }
  ]
}